{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Core Premise\n",
    "We currently have a model that uses 8 months of training data to generate predictions. We would like to experiment to see if a version of the model which trains on 4 months of training data to predict conversion in the following 2 month period could be viable, so that the lead time to use is reduced.\n",
    "\n",
    "In production, this could be used in such a way that the list of users predicted to convert within those two months can be placed on a priority list for a limited discount-promotions budget* Meanwhile, the data for the next round of predictions is being collected. \n",
    "\n",
    "For the purpose of the experiment, the available data will be divided into 6-month blocks, with the first 4 months of each block constituting the data collection period and the last two months constitutiing the performance period in which the target is whether or not a conversion took place. Subsets of these collection period + performance period pairs will be used for the training set, validation set, and test set respectively.\n",
    "\n",
    "**Exploratory data analysis of relationship between adwords promotions & conversion was low, so a different type of nudge is suggested here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing with Cutoff Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/3136096564.py:1: DtypeWarning: Columns (2,54) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  gstore = pd.read_csv(\"/Users/aoluwolerotimi/Datasets/train_dejsonified.csv\")\n"
     ]
    }
   ],
   "source": [
    "gstore = pd.read_csv(\"/Users/aoluwolerotimi/Datasets/train_dejsonified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gstore['date'] = pd.to_datetime(gstore['date'], format='%Y%m%d').dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest Date: 2016-08-01\n",
      "Latest Date: 2017-08-01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Earliest Date:\", (gstore['date']).min())\n",
    "print(\"Latest Date:\", (gstore['date']).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6-month split is end of Feb 2017. First set will be beginning of August to end of Feb, second set will be beginning of March to beginning of August"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = pd.to_datetime('2017-02-28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gstore['date'] = pd.to_datetime(gstore['date'])\n",
    "print(gstore['date'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = gstore.loc[gstore['date'] <= cutoff_date]\n",
    "df2 = gstore.loc[gstore['date'] > cutoff_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903653\n"
     ]
    }
   ],
   "source": [
    "print(df1.shape[0] + df2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data collection cutoff dates (4 months in)\n",
    "df1cutoff = pd.to_datetime('2016-11-30') \n",
    "df2cutoff = pd.to_datetime('2017-06-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set aside collection period and performance period data\n",
    "df1p = df1.loc[df1['date'] > df1cutoff]  # performance\n",
    "df1c = df1.loc[df1['date'] <= df1cutoff] # collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1trainids = df1c['fullVisitorId'].unique().tolist() # getting list of IDs for which we will check conversion in performance period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1train = pd.DataFrame(df1trainids, columns=['fullVisitorId']) # beginnning construction of training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['channelGrouping', 'date', 'fullVisitorId', 'sessionId',\n",
       "       'socialEngagementType', 'visitId', 'visitNumber', 'visitStartTime',\n",
       "       'continent', 'subContinent', 'country', 'region', 'metro', 'city',\n",
       "       'cityId', 'networkDomain', 'latitude', 'longitude', 'networkLocation',\n",
       "       'browser', 'browserVersion', 'browserSize', 'operatingSystem',\n",
       "       'operatingSystemVersion', 'isMobile', 'mobileDeviceBranding',\n",
       "       'mobileDeviceModel', 'mobileInputSelector', 'mobileDeviceInfo',\n",
       "       'mobileDeviceMarketingName', 'flashVersion', 'language', 'screenColors',\n",
       "       'screenResolution', 'deviceCategory', 'visits', 'hits', 'pageviews',\n",
       "       'bounces', 'newVisits', 'transactionRevenue', 'campaign', 'source',\n",
       "       'medium', 'keyword', 'adwordsClickInfo.criteriaParameters',\n",
       "       'isTrueDirect', 'referralPath', 'adwordsClickInfo.page',\n",
       "       'adwordsClickInfo.slot', 'adwordsClickInfo.gclId',\n",
       "       'adwordsClickInfo.adNetworkType', 'adwordsClickInfo.isVideoAd',\n",
       "       'adContent', 'campaignCode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gstore.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identified as variables which would not aid analysis in earlier EDA steps\n",
    "to_drop = ['socialEngagementType', 'networkDomain', 'latitude', 'longitude', 'networkLocation',\n",
    "       'browser', 'browserVersion', 'browserSize', 'operatingSystem',\n",
    "       'operatingSystemVersion', 'isMobile', 'mobileDeviceBranding',\n",
    "       'mobileDeviceModel', 'mobileInputSelector', 'mobileDeviceInfo',\n",
    "       'mobileDeviceMarketingName', 'flashVersion', 'language', 'screenColors',\n",
    "       'screenResolution', 'bounces', 'keyword', 'referralPath','campaignCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n",
      "/var/folders/z1/1zds15w97_g7_fhs4_83dc3m0000gn/T/ipykernel_63499/2759826767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1c.drop(col, axis=1, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "# to make parsing through df1c a bit more efficient\n",
    "for col in to_drop:\n",
    "    if col in df1c.columns:\n",
    "        df1c.drop(col, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create label for conversion in performance period\n",
    "\n",
    "# Step 1: Create a Boolean Series where True represents a non-null transactionRevenue\n",
    "converted_visitors = df1p['transactionRevenue'].notnull()\n",
    "\n",
    "# Step 2: Group by 'fullVisitorId' in df1p and check if any transactionRevenue entries are not null\n",
    "conversion_status = df1p[converted_visitors].groupby('fullVisitorId').size() > 0\n",
    "\n",
    "# Step 3: Map the conversion status back to df1c to create the 'targetConversion' column\n",
    "df1train['targetConversion'] = df1train['fullVisitorId'].map(conversion_status).fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning it into a function to reuse\n",
    "def conv_label(performance_df, groupby_col, result_df):\n",
    "    \"\"\"\n",
    "    Creates a 'targetConversion' column in the result DataFrame based on conversion data from the performance DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        performance_df (pd.DataFrame): DataFrame containing performance data, including 'transactionRevenue'.\n",
    "        groupby_col (str): Column name to group by, typically 'fullVisitorId'.\n",
    "        result_df (pd.DataFrame): DataFrame to which the 'targetConversion' results will be added.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The modified result DataFrame with a new 'targetConversion' column.\n",
    "    \"\"\"\n",
    "    # Step 1: Create a Boolean Series where True represents a non-null transactionRevenue\n",
    "    converted_visitors = performance_df['transactionRevenue'].notnull()\n",
    "\n",
    "    # Step 2: Group by the specified column in performance_df and check if any transactionRevenue entries are not null\n",
    "    conversion_status = performance_df[converted_visitors].groupby(groupby_col).size() > 0\n",
    "\n",
    "    # Step 3: Map the conversion status back to the result DataFrame to create the 'targetConversion' column\n",
    "    result_df['targetConversion'] = result_df[groupby_col].map(conversion_status).fillna(0).astype(int)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df1train['targetConversion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating column for if user visited for first time in collection period\n",
    "firstime_visitors = df1c['newVisits'].notnull()\n",
    "firstime_status = df1c[firstime_visitors].groupby('fullVisitorId').size() > 0\n",
    "df1train['newVisits'] = df1train['fullVisitorId'].map(firstime_status).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['channelGrouping', 'date', 'fullVisitorId', 'sessionId', 'visitId',\n",
       "       'visitNumber', 'visitStartTime', 'continent', 'subContinent', 'country',\n",
       "       'region', 'metro', 'city', 'cityId', 'deviceCategory', 'visits', 'hits',\n",
       "       'pageviews', 'newVisits', 'transactionRevenue', 'campaign', 'source',\n",
       "       'medium', 'adwordsClickInfo.criteriaParameters', 'isTrueDirect',\n",
       "       'adwordsClickInfo.page', 'adwordsClickInfo.slot',\n",
       "       'adwordsClickInfo.gclId', 'adwordsClickInfo.adNetworkType',\n",
       "       'adwordsClickInfo.isVideoAd', 'adContent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1c.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_encode = ['channelGrouping', 'deviceCategory', 'source']\n",
    "df1c = pd.get_dummies(df1c, columns=columns_to_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'fullVisitorId', 'sessionId', 'visitId', 'visitNumber',\n",
       "       'visitStartTime', 'continent', 'subContinent', 'country', 'region',\n",
       "       ...\n",
       "       'source_wanelo.com', 'source_wap.sogou.com', 'source_web.facebook.com',\n",
       "       'source_web.mail.comcast.net', 'source_web.telegram.org',\n",
       "       'source_wheretoget.it', 'source_xbidprodmirror.corp.google.com',\n",
       "       'source_yahoo', 'source_yandex', 'source_youtube.com'],\n",
       "      dtype='object', length=263)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1c.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {\n",
    "    'country': 'first',\n",
    "    'continent': 'first',\n",
    "    'subContinent': 'first',\n",
    "    'transactionRevenue': 'sum',\n",
    "    'pageviews': 'sum',\n",
    "    'isTrueDirect': 'sum'\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_columns = [col for col in df1c.columns if '_' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dummy_col in dummy_columns:\n",
    "    agg_dict[dummy_col] = 'sum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# making sure columns match\n",
    "incorrect_cols = [key for key in agg_dict if key not in df1c.columns]\n",
    "print(incorrect_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1c['isTrueDirect'] = df1c['isTrueDirect'].map({'true': 1}).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing an error\n",
    "isTrueDirect_column = df1.loc[df1['date'] <= df1cutoff, 'isTrueDirect']\n",
    "\n",
    "df1c['isTrueDirect'] = isTrueDirect_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    87254\n",
       "Name: isTrueDirect, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1c['isTrueDirect'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1c['isTrueDirect'] = df1c['isTrueDirect'].fillna(False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    270015\n",
       "1     87254\n",
       "Name: isTrueDirect, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1c['isTrueDirect'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "useragg = df1c.groupby('fullVisitorId').agg(agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might need to do outside: \n",
    "# count of how many times each visitor appears\n",
    "# count of non-null in transrev\n",
    "# visits where adwordsClickInfo.gclId is populated \n",
    "# visits where campaign is populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick test of type of object agg returns\n",
    "# aggtest = df1c.groupby('fullVisitorId').agg(agg_dict) # worked \n",
    "# aggtest = df1c.groupby('fullVisitorId').agg({'transactionRevenue': ['sum', ('conversions', lambda x: x.notnull().sum())]}) # did not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try doing it this way: create all the session level flags. then do the \"first\" based columns, then the count of visitorid columns, then all the group by aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating addiitonal columns which do not need encoding\n",
    "# Define the aggregation dictionary for all specified metrics and columns\n",
    "aggregations = {\n",
    "    'transactionRevenue': [\n",
    "        ('spend', 'sum'),  # Sum of transactionRevenue\n",
    "        ('conversions', lambda x: x.notnull().sum())  # Count non-null transactionRevenue\n",
    "    ],\n",
    "    'pageviews': [\n",
    "        ('pageViews', 'sum')  # Sum of pageviews\n",
    "    ],\n",
    "    'adwordsClickInfo.gclId': [\n",
    "        ('advisits', lambda x: x.notnull().sum())  # Count non-null adwordsClickInfo.gclId\n",
    "    ],\n",
    "    'campaign': [\n",
    "        ('campaignvisits', lambda x: x.notnull().sum())  # Count non-null campaign\n",
    "    ],\n",
    "    'isTrueDirect': [\n",
    "        ('directvisits', lambda x: x.notnull().sum())  # Count non-null isTrueDirect\n",
    "    ],\n",
    "    'continent': [\n",
    "        ('continent', 'first')  # Value of continent at the first appearance\n",
    "    ],\n",
    "    'subContinent': [\n",
    "        ('subcontinent', 'first')  # Value of subContinent at the first appearance\n",
    "    ],\n",
    "    'country': [\n",
    "        ('country', 'first')  # Value of country at the first appearance\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtest = df1c.groupby(['fullVisitorId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Must provide 'func' or tuples of '(column, aggfunc).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Perform the groupby and aggregate based on the specified aggregations\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m aggregated_data \u001b[38;5;241m=\u001b[39m \u001b[43mdf1c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfullVisitorId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maggregations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Flatten the MultiIndex columns created by the aggregation\u001b[39;00m\n\u001b[1;32m      5\u001b[0m aggregated_data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [col[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m aggregated_data\u001b[38;5;241m.\u001b[39mcolumns]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/groupby/generic.py:891\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    888\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39mresult_index\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_constructor(result, index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m--> 891\u001b[0m relabeling, func, columns, order \u001b[38;5;241m=\u001b[39m \u001b[43mreconstruct_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    892\u001b[0m func \u001b[38;5;241m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[1;32m    894\u001b[0m op \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/apply.py:1297\u001b[0m, in \u001b[0;36mreconstruct_func\u001b[0;34m(func, **kwargs)\u001b[0m\n\u001b[1;32m   1291\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SpecificationError(\n\u001b[1;32m   1292\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction names must be unique if there is no new column names \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1293\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massigned\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1294\u001b[0m         )\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;66;03m# nicer error message\u001b[39;00m\n\u001b[0;32m-> 1297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust provide \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or tuples of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(column, aggfunc).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[1;32m   1300\u001b[0m     func, columns, order \u001b[38;5;241m=\u001b[39m normalize_keyword_aggregation(kwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: Must provide 'func' or tuples of '(column, aggfunc)."
     ]
    }
   ],
   "source": [
    "# Perform the groupby and aggregate based on the specified aggregations\n",
    "aggregated_data = df1c.groupby('fullVisitorId').agg(**aggregations)\n",
    "\n",
    "# Flatten the MultiIndex columns created by the aggregation\n",
    "aggregated_data.columns = [col[1] for col in aggregated_data.columns]\n",
    "\n",
    "# Count of total visits by fullVisitorId\n",
    "aggregated_data['visits'] = df1c.groupby('fullVisitorId').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the aggregated data back into df1train\n",
    "df1train = df1train.merge(aggregated_data, on='fullVisitorId', how='left').fillna(0)\n",
    "\n",
    "# Optionally, convert counts and sums to integers if needed (from float due to NaN handling)\n",
    "columns_to_int = ['spend', 'pageViews', 'visits', 'conversions', 'advisits', 'campaignvisits', 'directvisits']\n",
    "df1train[columns_to_int] = df1train[columns_to_int].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gstore['medium'].value_counts()\n",
    "# # could investigate cpc later for uplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gstore['campaign'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gstore['campaignCode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aoluwolerotimi/anaconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create the OneHotEncoder instance\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Step 2: Fit and transform the data\n",
    "channel_encoded = encoder.fit_transform(df1c[['channelGrouping']])\n",
    "\n",
    "# Step 3: Convert the numpy array back to a DataFrame\n",
    "channel_encoded_df = pd.DataFrame(channel_encoded, columns=encoder.get_feature_names_out(['channelGrouping']))\n",
    "\n",
    "# Step 4: Concatenate the new dataframe with the original dataframe minus the original 'channelGrouping' column\n",
    "df1c = pd.concat([df1c.drop('channelGrouping', axis=1), channel_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1c.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = ['channelGrouping_(Other)', 'channelGrouping_Affiliates',\n",
    "       'channelGrouping_Direct', 'channelGrouping_Display',\n",
    "       'channelGrouping_Organic Search', 'channelGrouping_Paid Search',\n",
    "       'channelGrouping_Referral', 'channelGrouping_Social']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1train = df1train[['fullVisitorId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in cg:\n",
    "#     df1train[column] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              fullVisitorId  channelGrouping_(Other)  \\\n",
      "0       1131660440785968503                      0.0   \n",
      "1        377306020877927890                      0.0   \n",
      "2       3895546263509774583                      0.0   \n",
      "3       4763447161404445595                      0.0   \n",
      "4         27294437909732085                      0.0   \n",
      "...                     ...                      ...   \n",
      "299069  3118235170138318723                      0.0   \n",
      "299070  2900750270670203622                      0.0   \n",
      "299071  4821618326715417613                      0.0   \n",
      "299072  2720938310295703834                      0.0   \n",
      "299073   593617143165950851                      0.0   \n",
      "\n",
      "        channelGrouping_Affiliates  channelGrouping_Direct  \\\n",
      "0                              0.0                     0.0   \n",
      "1                              0.0                     0.0   \n",
      "2                              0.0                     0.0   \n",
      "3                              0.0                     0.0   \n",
      "4                              0.0                     0.0   \n",
      "...                            ...                     ...   \n",
      "299069                         0.0                     0.0   \n",
      "299070                         0.0                     0.0   \n",
      "299071                         0.0                     0.0   \n",
      "299072                         0.0                     0.0   \n",
      "299073                         0.0                     0.0   \n",
      "\n",
      "        channelGrouping_Display  channelGrouping_Organic Search  \\\n",
      "0                           0.0                             1.0   \n",
      "1                           0.0                             1.0   \n",
      "2                           0.0                             1.0   \n",
      "3                           0.0                             1.0   \n",
      "4                           0.0                             1.0   \n",
      "...                         ...                             ...   \n",
      "299069                      0.0                             0.0   \n",
      "299070                      0.0                             0.0   \n",
      "299071                      0.0                             0.0   \n",
      "299072                      0.0                             0.0   \n",
      "299073                      0.0                             0.0   \n",
      "\n",
      "        channelGrouping_Paid Search  channelGrouping_Referral  \\\n",
      "0                               0.0                       0.0   \n",
      "1                               0.0                       0.0   \n",
      "2                               0.0                       0.0   \n",
      "3                               0.0                       0.0   \n",
      "4                               0.0                       0.0   \n",
      "...                             ...                       ...   \n",
      "299069                          0.0                       0.0   \n",
      "299070                          0.0                       0.0   \n",
      "299071                          0.0                       0.0   \n",
      "299072                          0.0                       0.0   \n",
      "299073                          0.0                       0.0   \n",
      "\n",
      "        channelGrouping_Social  \n",
      "0                          0.0  \n",
      "1                          0.0  \n",
      "2                          0.0  \n",
      "3                          0.0  \n",
      "4                          0.0  \n",
      "...                        ...  \n",
      "299069                     0.0  \n",
      "299070                     0.0  \n",
      "299071                     0.0  \n",
      "299072                     0.0  \n",
      "299073                     0.0  \n",
      "\n",
      "[299074 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Group by 'fullVisitorId' in df1c and sum the columns in cg\n",
    "grouped = df1c.groupby('fullVisitorId')[cg].sum()\n",
    "\n",
    "# Step 2: Merge this grouped data back into df1train\n",
    "df1train = df1train.merge(grouped, on='fullVisitorId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Count occurrences of each 'fullVisitorId' in df1c\n",
    "visitor_counts = df1c['fullVisitorId'].value_counts().reset_index()\n",
    "visitor_counts.columns = ['fullVisitorId', 'totalVisits']\n",
    "\n",
    "# Step 2: Merge this count DataFrame back into df1train\n",
    "df1train = df1train.merge(visitor_counts, on='fullVisitorId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue later\n",
    "# df1c.to_csv('df1c.csv', index=True)\n",
    "# df1train.to_csv('df1train.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Channel grouping dummies then sum --> DONE\n",
    "* Count appearances of vistor id for total visits in period\n",
    "* First Continent, Suboncontinent, Country appearing\n",
    "* Device category dummies then summed\n",
    "* Sum of hits\n",
    "* Sum of pageviews\n",
    "* Flag for if new visitor in the period\n",
    "* Sum of transaction value in the period (might need to set nan to 0 first)\n",
    "* Source dummies then summed then PCA\n",
    "* Sum isTrueDirect\n",
    "* adWordsgclID sum not null \n",
    "* Sum campaign not null (set not set to null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
